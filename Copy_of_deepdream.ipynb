{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of deepdream.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAMES-YI/00_Tensorflow_Tutorials/blob/master/Copy_of_deepdream.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "1SgrstLXNbG_"
      },
      "source": [
        "Modified by JYI, 03/03/2020\n",
        "- patterns learned by other pre-trained models\n",
        "- application of the ideas\n",
        "- gradient calculation wrt input\n",
        "----\n",
        "Copyright 2019 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "k7gifg92NbG9",
        "colab": {}
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "dCMqzy7BNbG9"
      },
      "source": [
        "## Data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2yqCPS8SNbG8"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/generative/deepdream\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/deepdream.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/generative/deepdream.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XPDKhwPcNbG7"
      },
      "source": [
        "- implementation of DeepDream, as described in this [blog post](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html) by Alexander Mordvintsev.\n",
        "- DeepDream is an experiment that visualizes the patterns learned by a neural network. \n",
        "- It does so by forwarding an image through the network, then calculating the gradient of the image with respect to the activations of a particular layer. The image is then modified to increase these activations, enhancing the patterns seen by the network, and resulting in a dream-like image. \n",
        "\n",
        "![Dogception](https://www.tensorflow.org/tutorials/generative/images/dogception.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GUSXlFNkxrqh",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib as mpl\n",
        "\n",
        "import IPython.display as display\n",
        "import PIL.Image\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'\n",
        "# Download an image and read it into a NumPy array.\n",
        "def download(url, max_dim=None):\n",
        "  name = url.split('/')[-1]\n",
        "  image_path = tf.keras.utils.get_file(name, origin=url)\n",
        "  img = PIL.Image.open(image_path)\n",
        "  if max_dim:\n",
        "    img.thumbnail((max_dim, max_dim))\n",
        "  return np.array(img)\n",
        "\n",
        "# Normalize an image\n",
        "def deprocess(img):\n",
        "  img = 255*(img + 1.0)/2.0\n",
        "  return tf.cast(img, tf.uint8)\n",
        "\n",
        "# Display an image\n",
        "def show(img):\n",
        "  display.display(PIL.Image.fromarray(np.array(img)))\n",
        "\n",
        "\n",
        "# Downsizing the image makes it easier to work with.\n",
        "original_img = download(url, max_dim=500)\n",
        "show(original_img)\n",
        "display.display(display.HTML('Image cc-by: <a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka</a>'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "F4RBFfIWNbG0"
      },
      "source": [
        "## Prepare the feature extraction model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bujb0jPNNbGx"
      },
      "source": [
        "- choose a layer (or layers) and maximize the \"loss\" in a way that the image increasingly \"excites\" the layers\n",
        "- characterization of maximal excitation of layers\n",
        "- The complexity of the features incorporated depends on layers chosen by you, i.e, lower layers produce strokes or simple patterns, while deeper layers give sophisticated features in images, or even whole objects.\n",
        "- layers of  interest are those where the convolutions are concatenated. There are 11 of these layers in InceptionV3, named 'mixed0' though 'mixed10'.\n",
        "- Feel free to experiment with the layers selected below, but keep in mind that deeper layers (those with a higher index) will take longer to train on since the gradient computation is deeper.\n",
        "- The loss is the sum of the activations in the chosen layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "08KB502ONbGt",
        "colab": {}
      },
      "source": [
        "'''\n",
        "- exploration of tf.keras.applications.InceptionV3 and other pre-trained models\n",
        "- select layers\n",
        "- calculate loss, simply maximize the sum of activation outputs\n",
        "'''\n",
        "\n",
        "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
        "# Maximize the activations of these layers\n",
        "names = ['mixed3', 'mixed5']\n",
        "layers = [base_model.get_layer(name).output for name in names]\n",
        "\n",
        "# Create the feature extraction model\n",
        "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
        "\n",
        "def calc_loss(img, model):\n",
        "  # Pass forward the image through the model to retrieve the activations.\n",
        "  # Converts the image into a batch of size 1.\n",
        "  img_batch = tf.expand_dims(img, axis=0)\n",
        "  layer_activations = model(img_batch)\n",
        "  if len(layer_activations) == 1:\n",
        "    layer_activations = [layer_activations]\n",
        "\n",
        "  losses = []\n",
        "  for act in layer_activations:\n",
        "    loss = tf.math.reduce_mean(act)\n",
        "    losses.append(loss)\n",
        "\n",
        "  return  tf.reduce_sum(losses)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k4TCNsAUO9kI"
      },
      "source": [
        "## Gradient ascent and activation excitation\n",
        "\n",
        "- uses an `input_signature` to ensure that the function is not retraced for different image sizes or `steps`/`step_size` values. See the [Concrete functions guide](../../guide/concrete_function.ipynb) for details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qRScWg_VNqvj",
        "colab": {}
      },
      "source": [
        "'''\n",
        "- tf.Module\n",
        "- __call__, take input image, return the output image which can maximally excite the selected layer\n",
        "- input_signature, specify the shape and type of each input arguments to the function\n",
        "- tf.GradientTap().watch(x), use x as optimization variable\n",
        "- tf.keras.applications.inception_v3.preprocess_input(img), preprocess an image\n",
        "- run the optimizer and update images\n",
        "'''\n",
        "class DeepDream(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function(\n",
        "      input_signature=(\n",
        "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.int32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
        "  )\n",
        "  def __call__(self, img, steps, step_size):\n",
        "      print(\"Tracing\")\n",
        "      loss = tf.constant(0.0)\n",
        "      for n in tf.range(steps):\n",
        "        with tf.GradientTape() as tape:\n",
        "          # This needs gradients relative to `img`\n",
        "          # `GradientTape` only watches `tf.Variable`s by default\n",
        "          tape.watch(img)\n",
        "          loss = calc_loss(img, self.model)\n",
        "\n",
        "        # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
        "        gradients = tape.gradient(loss, img)\n",
        "\n",
        "        # Normalize the gradients.\n",
        "        gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
        "        \n",
        "        # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
        "        # You can update the image by directly adding the gradients (because they're the same shape!)\n",
        "        img = img + gradients*step_size\n",
        "        img = tf.clip_by_value(img, -1, 1)\n",
        "\n",
        "      return loss, img\n",
        "\n",
        "deepdream = DeepDream(dream_model)\n",
        "\n",
        "def run_deep_dream_simple(img, steps=100, step_size=0.01):\n",
        "  # Convert from uint8 to the range expected by the model.\n",
        "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "  img = tf.convert_to_tensor(img)\n",
        "  step_size = tf.convert_to_tensor(step_size)\n",
        "  steps_remaining = steps\n",
        "  step = 0\n",
        "  while steps_remaining:\n",
        "    if steps_remaining>100:\n",
        "      run_steps = tf.constant(100)\n",
        "    else:\n",
        "      run_steps = tf.constant(steps_remaining)\n",
        "    steps_remaining -= run_steps\n",
        "    step += run_steps\n",
        "\n",
        "    loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
        "    \n",
        "    display.clear_output(wait=True)\n",
        "    show(deprocess(img))\n",
        "    print (\"Step {}, loss {}\".format(step, loss))\n",
        "\n",
        "\n",
        "  result = deprocess(img)\n",
        "  display.clear_output(wait=True)\n",
        "  show(result)\n",
        "\n",
        "  return result\n",
        "\n",
        "dream_img = run_deep_dream_simple(img=original_img, \n",
        "                                  steps=100, step_size=0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2PbfXEVFNbGp"
      },
      "source": [
        "## Taking it up an octave\n",
        "\n",
        "- The output is noisy (this could be addressed with a `tf.image.total_variation` loss).\n",
        "- The image is low resolution.\n",
        "- The patterns appear like they're all happening at the same granularity.\n",
        "- applying gradient ascent at different scales. This will allow patterns generated at smaller scales to be incorporated into patterns at higher scales and filled in with additional detail.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0eGDSdatLT-8",
        "colab": {}
      },
      "source": [
        "'''\n",
        "- image is rescaled\n",
        "- run the optimization and get new dream image\n",
        "'''\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "OCTAVE_SCALE = 1.30\n",
        "\n",
        "img = tf.constant(np.array(original_img))\n",
        "base_shape = tf.shape(img)[:-1]\n",
        "float_base_shape = tf.cast(base_shape, tf.float32)\n",
        "\n",
        "for n in range(-2, 3):\n",
        "  new_shape = tf.cast(float_base_shape*(OCTAVE_SCALE**n), tf.int32)\n",
        "\n",
        "  img = tf.image.resize(img, new_shape).numpy()\n",
        "\n",
        "  img = run_deep_dream_simple(img=img, steps=50, step_size=0.01)\n",
        "\n",
        "display.clear_output(wait=True)\n",
        "img = tf.image.resize(img, base_shape)\n",
        "img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
        "show(img)\n",
        "\n",
        "end = time.time()\n",
        "end-start"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "s9xqyeuwLZFy"
      },
      "source": [
        "## Optional: Scaling up with tiles\n",
        "\n",
        "- split the image into tiles and compute the gradient for each tile to handle large image.\n",
        "- [TensorFlow Lucid](https://github.com/tensorflow/lucid) which expands on ideas introduced in this tutorial to visualize and interpret neural networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oGgLHk7o80ac",
        "colab": {}
      },
      "source": [
        "'''\n",
        "- shift images to get new image\n",
        "- purpose of rolling and tiling, calculate gradients of functions part by part\n",
        "'''\n",
        "def random_roll(img, maxroll):\n",
        "  # Randomly shift the image to avoid tiled boundaries.\n",
        "  shift = tf.random.uniform(shape=[2], minval=-maxroll, maxval=maxroll, dtype=tf.int32)\n",
        "  shift_down, shift_right = shift[0],shift[1] \n",
        "  img_rolled = tf.roll(tf.roll(img, shift_right, axis=1), shift_down, axis=0)\n",
        "  return shift_down, shift_right, img_rolled\n",
        "\n",
        "shift_down, shift_right, img_rolled = random_roll(np.array(original_img), 512)\n",
        "show(img_rolled)\n",
        "\n",
        "class TiledGradients(tf.Module):\n",
        "  def __init__(self, model):\n",
        "    self.model = model\n",
        "\n",
        "  @tf.function(\n",
        "      input_signature=(\n",
        "        tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
        "        tf.TensorSpec(shape=[], dtype=tf.int32),)\n",
        "  )\n",
        "  def __call__(self, img, tile_size=512):\n",
        "    shift_down, shift_right, img_rolled = random_roll(img, tile_size)\n",
        "\n",
        "    # Initialize the image gradients to zero.\n",
        "    gradients = tf.zeros_like(img_rolled)\n",
        "    \n",
        "    # Skip the last tile, unless there's only one tile.\n",
        "    xs = tf.range(0, img_rolled.shape[0], tile_size)[:-1]\n",
        "    if not tf.cast(len(xs), bool):\n",
        "      xs = tf.constant([0])\n",
        "    ys = tf.range(0, img_rolled.shape[1], tile_size)[:-1]\n",
        "    if not tf.cast(len(ys), bool):\n",
        "      ys = tf.constant([0])\n",
        "    \n",
        "    '''\n",
        "    - loss is defined for \n",
        "    '''\n",
        "\n",
        "    for x in xs:\n",
        "      for y in ys:\n",
        "        # Calculate the gradients for this tile.\n",
        "        with tf.GradientTape() as tape:\n",
        "          # This needs gradients relative to `img_rolled`.\n",
        "          # `GradientTape` only watches `tf.Variable`s by default.\n",
        "          tape.watch(img_rolled)\n",
        "\n",
        "          # Extract a tile out of the image.\n",
        "          img_tile = img_rolled[x:x+tile_size, y:y+tile_size]\n",
        "          loss = calc_loss(img_tile, self.model)\n",
        "\n",
        "        # Update the image gradients for this tile.\n",
        "        gradients = gradients + tape.gradient(loss, img_rolled)\n",
        "\n",
        "    # Undo the random shift applied to the image and its gradients.\n",
        "    gradients = tf.roll(tf.roll(gradients, -shift_right, axis=1), -shift_down, axis=0)\n",
        "\n",
        "    # Normalize the gradients.\n",
        "    gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
        "\n",
        "    return gradients \n",
        "  \n",
        "get_tiled_gradients = TiledGradients(dream_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gA-15DM4NbGk",
        "colab": {}
      },
      "source": [
        "'''\n",
        "- octaves, -2, -1, 0, 1, 2; each is a scaling factor for the size of image\n",
        "- scale the original image to new size\n",
        "- calculate tiled gadients\n",
        "- update images\n",
        "'''\n",
        "def run_deep_dream_with_octaves(img, steps_per_octave=100, step_size=0.01, \n",
        "                                octaves=range(-2,3), octave_scale=1.3):\n",
        "  base_shape = tf.shape(img)\n",
        "  img = tf.keras.preprocessing.image.img_to_array(img)\n",
        "  img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
        "\n",
        "  initial_shape = img.shape[:-1]\n",
        "  img = tf.image.resize(img, initial_shape)\n",
        "  for octave in octaves:\n",
        "    # Scale the image based on the octave\n",
        "    new_size = tf.cast(tf.convert_to_tensor(base_shape[:-1]), tf.float32)*(octave_scale**octave)\n",
        "    img = tf.image.resize(img, tf.cast(new_size, tf.int32))\n",
        "\n",
        "    for step in range(steps_per_octave):\n",
        "      gradients = get_tiled_gradients(img)\n",
        "      img = img + gradients*step_size\n",
        "      img = tf.clip_by_value(img, -1, 1)\n",
        "\n",
        "      if step % 10 == 0:\n",
        "        display.clear_output(wait=True)\n",
        "        show(deprocess(img))\n",
        "        print (\"Octave {}, Step {}\".format(octave, step))\n",
        "    \n",
        "  result = deprocess(img)\n",
        "  return result\n",
        "\n",
        "img = run_deep_dream_with_octaves(img=original_img, step_size=0.01)\n",
        "\n",
        "display.clear_output(wait=True)\n",
        "img = tf.image.resize(img, base_shape)\n",
        "img = tf.image.convert_image_dtype(img/255.0, dtype=tf.uint8)\n",
        "show(img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}